{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Input, GRU, LSTM, Dense, Masking, Dropout, Embedding, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_DIGITS = 4\n",
    "QUANTIZATION = 12  # smallest unit is 1/12 of a beat\n",
    "MAX_EVENT_BEATS = 4\n",
    "\n",
    "MIDI_MIN = 21\n",
    "MIDI_MAX = 108\n",
    "\n",
    "MAX_EVENT_SUBBEATS = QUANTIZATION * MAX_EVENT_BEATS\n",
    "\n",
    "MIDI_LEN = MIDI_MAX - MIDI_MIN + 1  # 88 keys\n",
    "\n",
    "# One-hot vector lengths\n",
    "NUM_COMMAND_CLASSES = 3\n",
    "NUM_MIDI_CLASSES = MIDI_LEN + 1                # + 1 for \"0\" case\n",
    "NUM_DURATION_CLASSES = MAX_EVENT_SUBBEATS + 1  # + 1 for \"0\" case\n",
    "\n",
    "# Start of range is inclusive, end of range is exclusive. \n",
    "COMMAND_VEC_RANGE = (0, NUM_COMMAND_CLASSES)\n",
    "MIDI_VEC_RANGE = (COMMAND_VEC_RANGE[1], COMMAND_VEC_RANGE[1] + NUM_MIDI_CLASSES)\n",
    "DURATION_VEC_RANGE = (MIDI_VEC_RANGE[1], MIDI_VEC_RANGE[1] + NUM_DURATION_CLASSES)\n",
    "VEC_LENGTH = DURATION_VEC_RANGE[1]\n",
    "COMMAND_VEC_RANGE, MIDI_VEC_RANGE, DURATION_VEC_RANGE, VEC_LENGTH\n",
    "\n",
    "INPUT_NOTES = 30\n",
    "OUTPUT_NOTES = 10\n",
    "SLIDING_WINDOW_NOTES = 5\n",
    "\n",
    "INPUT_TIMESTEPS = 4 * INPUT_NOTES\n",
    "OUTPUT_TIMESTEPS = 4 * OUTPUT_NOTES\n",
    "SLIDING_WINDOW_TIMESTEPS = 4 * SLIDING_WINDOW_NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LSTM_NODES = 256             # Num of intermediate LSTM nodes\n",
    "CONTEXT_VECTOR_SIZE = 256        # Size of context vector (num of LSTM nodes in final LSTM layer)\n",
    "\n",
    "EMBEDDING_DIM = 100              # Embedding layer size for input words\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "LR = 0.01\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/data/mirex2018/train_pkl/train*pkl'\n",
    "TEST_PATH = '/data/mirex2018/test_pkl/test*pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(pickle_filename):\n",
    "    \"\"\"Returns tuple of train_matrix, test_matrix, holding many examples.\n",
    "    Ex: two matrix shapes returned: (561, 120, 141), (561, 40, 141).\n",
    "    dims are: (example #, timestep, feature)\n",
    "    \"\"\"\n",
    "    x_list, y_list = joblib.load(pickle_filename) \n",
    "    return np.vstack(x_list), np.vstack(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = sorted(glob.glob(TRAIN_PATH))\n",
    "TEST_FILES = sorted(glob.glob(TEST_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_generator(train=True):\n",
    "    files = TRAIN_FILES if train else TEST_FILES\n",
    "    \n",
    "    while True:\n",
    "        for file in files:\n",
    "            x, y = load_dataset(file)\n",
    "            yield x, y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = example_generator()\n",
    "validation_generator = example_generator(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(x):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(x, origin='lower')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN model.\n",
    "# See also: https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/\n",
    "\n",
    "encoding_size = CONTEXT_VECTOR_SIZE\n",
    "max_input_seq_len = max_seq_len_X\n",
    "max_output_seq_len = max_seq_len_y\n",
    "num_input_words = num_words_X\n",
    "num_output_words = num_words_y\n",
    "\n",
    "encoder_inputs = Input(shape=(max_input_seq_len,), name='encoder_input')\n",
    "encoder_inputs_masked = Masking(mask_value=0, name='encoder_masking')(encoder_inputs)\n",
    "encoder_inputs_embedded = Embedding(num_input_words, EMBEDDING_DIM, mask_zero=True, name='encoder_embedding')(encoder_inputs_masked)\n",
    "encoder_outputs1, state_h1, state_c1 = LSTM(NUM_LSTM_NODES, return_sequences=True, return_state=True,\n",
    "                                            name='encoder_lstm_1')(encoder_inputs_embedded)\n",
    "\n",
    "# Discard `encoder_outputs2` and only keep the states.\n",
    "encoder_states1 = [state_h1, state_c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder section\n",
    "# Set up the decoder, using encoder_states as initial state.\n",
    "decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
    "decoder_inputs_masked = Masking(mask_value=0, name='decoder_masking')(decoder_inputs)\n",
    "decoder_inputs_embedded = Embedding(num_output_words, EMBEDDING_DIM, mask_zero=True, \n",
    "                                    name='decoder_embedding')(decoder_inputs_masked)\n",
    "decoder_lstm = LSTM(NUM_LSTM_NODES, return_sequences=True, return_state=True, name='decoder_lstm_1')\n",
    "z, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=encoder_states1)\n",
    "decoder_dense = Dense(num_output_words, activation='softmax', name='decoder_output')\n",
    "decoder_outputs = decoder_dense(z)\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = X_train\n",
    "decoder_input_data = y_train\n",
    "\n",
    "# decoder_target_data will be ahead by one timestep\n",
    "# and will not include the start token.\n",
    "decoder_target_data = np.zeros(y_train_one_hot.shape)\n",
    "decoder_target_data[:,:-1] = y_train_one_hot[:,1\n",
    "                                             \n",
    "decoder_target_data_test = np.zeros(y_test_one_hot.shape)\n",
    "decoder_target_data_test[:,:-1] = y_test_one_hot[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='auto', \n",
    "                                cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.fit_generator(training_generator, steps_per_epoch=50000,  # TODO\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=20000, # TODO\n",
    "                       verbose=1,\n",
    "                       workers=1,\n",
    "                       use_multiprocessing=False,\n",
    "                    \n",
    "                 #   [encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=NUM_EPOCHS,\n",
    "                      #validation_data=([X_test, y_test], decoder_target_data_test),\n",
    "                      callbacks=[lr_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states1)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(encoder_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(NUM_LSTM_NODES,))\n",
    "decoder_state_input_c = Input(shape=(NUM_LSTM_NODES,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs1, state_h1, state_c1 = decoder_lstm(\n",
    "    decoder_inputs_embedded, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states1 = [state_h1, state_c1]\n",
    "decoder_outputs = decoder_dense(decoder_outputs1)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states1)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(decoder_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    h1, c1 = encoder_model.predict(input_seq)\n",
    "    states_value1 = [h1, c1]\n",
    "    # Generate empty target sequence of length 1 (one-hot encoded).\n",
    "    #target_seq = np.zeros((1, num_output_words))\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first word of target sequence with the start symbol.\n",
    "    #target_seq[0, word_to_index2['<S>']] = 1.\n",
    "    target_seq[0,0] = word_to_index2['<S>']\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    step = 0\n",
    "    while not stop_condition:\n",
    "        #print('step:', step)\n",
    "        #print(states_value1[0][0][0:5])\n",
    "    \n",
    "        output_tokens, h1, c1  = decoder_model.predict(\n",
    "            [target_seq] + states_value1)\n",
    "\n",
    "        # Sample a token\n",
    "        #print(output_tokens)\n",
    "        #sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_word = index_to_word2[sampled_token_index]\n",
    "        #print(sampled_word)\n",
    "        decoded_sentence += sampled_word + ' '\n",
    "        step += 1\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '</S>' or step > max_output_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        #target_seq = np.zeros((1, num_output_words))\n",
    "        #target_seq[0, sampled_token_index] = 1.\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update states\n",
    "        states_value1 = [h1, c1]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(translate_sequence(np.expand_dims(X_test[i], axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
